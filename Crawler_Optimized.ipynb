{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import URL, DOM, plaintext, Element, extension, Crawler, DEPTH\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import PIL\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scraper():\n",
    "    def save_image(self):\n",
    "        pass\n",
    "    def get_recipe(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllRecipesScraper(Scraper):\n",
    "    \n",
    "    def save_image(self,element,idx,basewidth = 300):\n",
    "        first_rec_photo = element.by_class(\"rec-photo\")[0]\n",
    "        url = first_rec_photo.attributes.get('src','')\n",
    "        if '/nophoto/nopicture' not in url:\n",
    "            img_url = URL(url)\n",
    "            img = Image.open(img_url)\n",
    "            wpercent = (basewidth / float(img.size[0]))\n",
    "            hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "            img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "            img.save(\"img/\"+str(idx) + extension(img_url.page))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    def get_ingredients(self,element):\n",
    "        ing_nodes = element.by_class(\"recipe-ingred_txt added\")\n",
    "        return \"\\n\".join([plaintext(a.content) for a in ing_nodes])\n",
    "\n",
    "    \n",
    "    def get_instructions(self,element):\n",
    "        instr_nodes = element.by_class(\"recipe-directions__list--item\")\n",
    "        return \"\\n\".join([plaintext(a.content) for a in instr_nodes])\n",
    "    \n",
    "    def get_recipe(self,element):\n",
    "        return self.get_ingredients(element)+\"\\n\"+self.get_instructions(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllRecipesRandomSearch():\n",
    "    def __init__(self,tried_ids = None, recipe_list = None ):\n",
    "        self.scraper = AllRecipesScraper()\n",
    "        if tried_ids is None:\n",
    "            self.tried_ids = set()\n",
    "        else:\n",
    "            self.tried_ids = tried_ids\n",
    "        if recipe_list is None:\n",
    "            self.recipe_list = {}\n",
    "        else:\n",
    "            self.recipe_list = recipe_list\n",
    "        self.count = 0\n",
    "        \n",
    "    def reset_count(self):\n",
    "        self.count = 0\n",
    "        \n",
    "    def new_id(self,rec_id):\n",
    "        return rec_id not in self.tried_ids\n",
    "          \n",
    "    def visit(self,rec_id):\n",
    "        url = URL(\"http://allrecipes.com/recipe/\"+str(rec_id))\n",
    "        try:\n",
    "            source = url.download(cached=True)\n",
    "            self.scrape(source, rec_id)\n",
    "        except Exception as detail:\n",
    "            print 'Unable to Scrape:', rec_id\n",
    "            self.tried_ids.add(rec_id)\n",
    "            \n",
    "    def scrape(self,source,rec_id):\n",
    "        print(\"scraping\", rec_id)\n",
    "        element = Element(source)\n",
    "        recipe = self.scraper.get_recipe(element)\n",
    "        if \"Top pizza crust with cheese. Bake crust according to package directions. Meanwhile, in a 12-inch skillet\" not in recipe:\n",
    "            saved = self.scraper.save_image(element, rec_id)\n",
    "            if saved:\n",
    "                self.recipe_list[rec_id]=recipe\n",
    "            else:\n",
    "                print \"Image less recipe \"\n",
    "        else:\n",
    "            print \"Random Cheese page \"\n",
    "        self.tried_ids.add(rec_id)\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9333\n",
      "Check point Iter: 0\n",
      "('scraping', 119073)\n",
      "Image less recipe \n",
      "('scraping', 179837)\n",
      "Image less recipe \n",
      "('scraping', 124157)\n",
      "Image less recipe \n",
      "('scraping', 106749)\n",
      "Image less recipe \n",
      "('scraping', 188869)\n",
      "Random Cheese page \n",
      "('scraping', 155330)\n",
      "Random Cheese page \n",
      "('scraping', 175691)\n",
      "Random Cheese page \n",
      "('scraping', 109994)\n",
      "Random Cheese page \n",
      "('scraping', 125960)\n",
      "Image less recipe \n",
      "('scraping', 149975)\n",
      "('scraping', 148860)\n",
      "Random Cheese page \n",
      "('scraping', 170916)\n",
      "Random Cheese page \n",
      "('scraping', 183658)\n",
      "Random Cheese page \n",
      "('scraping', 185954)\n",
      "Random Cheese page \n",
      "('scraping', 168955)\n",
      "Random Cheese page \n",
      "('scraping', 114072)\n"
     ]
    }
   ],
   "source": [
    "tried_ids = pickle.load(open(\"tried_ids_final.p\",\"rb\"))\n",
    "recipe_list = pickle.load(open(\"recipes_final.p\",\"rb\"))\n",
    "\n",
    "print len(tried_ids)\n",
    "\n",
    "search = AllRecipesRandomSearch(tried_ids,recipe_list)\n",
    "limit =3000\n",
    "\n",
    "while search.count < limit:\n",
    "    if search.count%100 ==0:\n",
    "        print \"Check point Iter: %s\"%search.count\n",
    "        pickle.dump( search.recipe_list, open( \"recipes\"+str(search.count/500)+\".p\", \"wb\" ) )\n",
    "        pickle.dump( search.tried_ids, open( \"tried_ids\"+str(search.count/500)+\".p\", \"wb\" ) )\n",
    "    rec_id = random.randint(100000,200000)\n",
    "    if search.new_id(rec_id):\n",
    "        search.visit(rec_id)\n",
    "    time.sleep(1)\n",
    "\n",
    "print \"Saving the final work\"\n",
    "pickle.dump( search.recipe_list, open( \"recipes_final.p\", \"wb\" ) )\n",
    "pickle.dump( search.tried_ids, open( \"tried_ids_final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
