{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import URL, DOM, plaintext, Element, extension, Crawler, DEPTH\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scraper():\n",
    "    def save_image(self):\n",
    "        pass\n",
    "    def get_recipe(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllRecipesScraper(Scraper):\n",
    "    def save_image(self,element,idx,basewidth = 300):\n",
    "        print(\"Saving image\",idx)\n",
    "        first_rec_photo = element.by_class(\"rec-photo\")[0]\n",
    "        url = first_rec_photo.attributes.get('src','')\n",
    "        img_url = URL(url)\n",
    "        img = Image.open(img_url)\n",
    "        wpercent = (basewidth / float(img.size[0]))\n",
    "        hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "        img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "        img.save(\"img/\"+str(idx) + extension(img_url.page))\n",
    "        \n",
    "    def get_ingredients(self,element):\n",
    "        ing_nodes = element.by_class(\"recipe-ingred_txt added\")\n",
    "        return \"\\n\".join([plaintext(a.content) for a in ing_nodes \n",
    "                          if \"Add all ingredients to list\" not in plaintext(a.content)])\n",
    "\n",
    "    \n",
    "    def get_instructions(self,element):\n",
    "        instr_nodes = element.by_class(\"recipe-directions__list--item\")\n",
    "        return \"\\n\".join([plaintext(a.content) for a in instr_nodes])\n",
    "    \n",
    "    def get_recipe(self,element):\n",
    "        return self.get_ingredients(element)+\"\\n\"+self.get_instructions(element)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AllRecipesCrawler(Crawler):\n",
    "    def __init__(self,links, delay,recipe_list = None):\n",
    "        super( AllRecipesCrawler, self ).__init__(links=links, delay=delay)\n",
    "        self.scraper = AllRecipesScraper()\n",
    "        if recipe_list is None:\n",
    "            self.recipe_list = {}\n",
    "        else:\n",
    "            self.recipe_list = recipe_list\n",
    "        self.count = 0\n",
    "        \n",
    "        \n",
    "    def reset_count(self):\n",
    "        self.count = 0\n",
    "        \n",
    "    def follow(self, link):\n",
    "        if \"recipes/\" in str(link.url):\n",
    "            yield True\n",
    "        else:\n",
    "            yield False\n",
    "            \n",
    "    def visit(self, link, source=None):\n",
    "        if \"recipe/\" in str(link.url):\n",
    "            print(\"visiting\", str(link.url),self.count)\n",
    "            try:\n",
    "                rec_id = re.search(\".*recipe/(.*)(/.*/)+\", str(link.url)).group(1)\n",
    "                if rec_id not in self.recipe_list.keys():\n",
    "                    self.scrape(source, rec_id)\n",
    "                else:\n",
    "                    print(\"already scraped\",rec_id)\n",
    "            except Exception as detail:\n",
    "                print 'Run-time error:', detail\n",
    "            \n",
    "            \n",
    "    def scrape(self,source,rec_id):\n",
    "        print(\"scraping\", rec_id)\n",
    "        element = Element(source)\n",
    "        try:\n",
    "            recipe = self.scraper.get_recipe(element)\n",
    "            self.scraper.save_image(element, rec_id)\n",
    "            self.recipe_list[rec_id]=recipe\n",
    "            self.count += 1\n",
    "        except Exception as detail:\n",
    "            print 'Handling run-time error:', detail\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rerun this code every time\n",
    "crawler.reset_count()\n",
    "limit = 2\n",
    "while (not crawler.done) and crawler.count < limit:\n",
    "    crawler.crawl(method=DEPTH, cached=False)\n",
    "save_as = \"recipe_lists/recipe_list\"+str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))+\".p\"\n",
    "pickle.dump( crawler.recipe_list, open(save_as , \"wb\" ) ) \n",
    "print \"Saved as\", save_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In case of kernel restart run this (need to combined saved dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipe_list = pickle.load( open( \"recipe_lists/recipe_list2016-04-24 16:55.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url = \"http://allrecipes.com/\"\n",
    "limit = 5000\n",
    "crawler = AllRecipesCrawler(links=[base_url], delay=1,recipe_list = recipe_list )\n",
    "crawler.reset_count()\n",
    "while (not crawler.done) and crawler.count < limit:\n",
    "    crawler.crawl(method=DEPTH, cached=False)\n",
    "save_as = \"recipe_lists/recipe_list\"+str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))+\".p\"\n",
    "pickle.dump( crawler.recipe_list, open(save_as , \"wb\" ) ) \n",
    "print \"Saved as\", save_as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
